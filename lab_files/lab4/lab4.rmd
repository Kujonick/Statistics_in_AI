---
title: "lab4"
author: "Hubert Guzowski"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

### Uogólnione modele liniowe

W statystyce dopasowujemy model do zaobserwowanych danych. Na podstawie
uprzedniej wiedzy możemy założyć, że model przyjmie pewną postać.
Przykładowo w regresji liniowej zakładamy, że istnieje pewna liniowa
kombinacja wektora predyktorów, która przewidzi/objaśni zmienną
objaśnianą z dokładnością do pewnego szumu losowego. Oczywiście nie
wszystkie zmienne objaśniane będą pasowały do takiego modelu. Aby
odpowiednio zamodelować relację, będzie więc potrzebne zastosowanie
funkcji mapującej.

### Regresja logistyczna

Zgodnie z nazwą regrezja logistyczna opiera się o funkcję mapującą
logit:\
$$
Y \sim \text{ln}\left(\frac{e^{\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p}}{1 + e^{\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p}}\right)
$$

```{r sample poisson}
library(ggplot2)

# Symulujemy dane
set.seed(123) # Dla powtarzalności
X <- rnorm(100)
log_odds <- -2 + 3 * X
p <- plogis(log_odds)
Y <- rbinom(100, 1, p)

# Dopasowujemy model. Nazwę rozkładu dostarczamu w argumencie rodziny modeli
model <- glm(Y ~ X, family = binomial)
pred_probs <- predict(model, type = "response")  # Przewidziane prawdopodobieństwa

# Granica decyzyjna (gdzie przedidziane prawdopodobieństwo = 0.5)
decision_boundary <- -coef(model)[1] / coef(model)[2]

# Wizualizacja
ggplot(data.frame(X, Y, pred_probs), aes(X)) +
  geom_jitter(aes(y = Y), width = 0.05, height = 0.05, 
              shape = 21, size = 2, fill = "gray70", alpha = 0.7) +
  geom_line(aes(y = pred_probs), color = "blue", linewidth = 1) +
  geom_vline(xintercept = decision_boundary, linetype = "dashed", color = "red") +
  annotate("point", x = decision_boundary, y = 0.5, size = 3, color = "red") +
  annotate("text", x = decision_boundary, y = 0.7, 
           label = paste0("X = ", round(decision_boundary, 2)), color = "red") +
  scale_y_continuous(limits = c(-0.1, 1.1), breaks = c(0, 0.5, 1)) +
  labs(title = "Logistic Regression with Decision Boundary",
       y = "Probability (Predicted) / Outcome (Observed)",
       x = "Predictor Variable") +
  theme_minimal()
```

Wykorzystamy zbiór danych Titanic, zawierający dane pasażerów statku
oraz informację o tym, czy przeżyli katastrofę.

```{r load titanic}
titanic_data <- read.csv("https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv")  

summary(titanic_data)  
```

Aby ocenić jakość modelu klasyfikacji, dokonujemy podziału na zbiór
treningowy i testowy.

```{r split}
set.seed(123)

train_indices <- sample(1:nrow(titanic_data), size = 0.7 * nrow(titanic_data))

train_data <- titanic_data[train_indices, -3] # Usuwamy imiona
test_data  <- titanic_data[-train_indices, -3]

cat("Training set:", nrow(train_data), "rows\n",
    "Test set:", nrow(test_data), "rows")
```

Dopasowujemy model do wszystkich zmiennych:

```{r fit model}
titanic_model <- glm(Survived ~ ., family = binomial, data = train_data)
summary(titanic_model)
```

```{r predict titanic}
titanic_pred <- predict(titanic_model, newdata = test_data, type = "response")
predicted_classes <- ifelse(titanic_pred > 0.5, 1, 0)
confusion_matrix <- table(Predicted = predicted_classes, Actual = test_data$Survived)
print(confusion_matrix)
```

```{r metrics}
tp <- confusion_matrix[2,2]  # True positives
tn <- confusion_matrix[1,1]  # True negatives
fp <- confusion_matrix[2,1]  # False positives
fn <- confusion_matrix[1,2]  # False negatives

accuracy <- (tp + tn) / sum(confusion_matrix)
precision <- tp / (tp + fp)
recall <- tp / (tp + fn)
specificity <- tn / (tn + fp)
f1_score <- 2 * (precision * recall) / (precision + recall)

cat("\nPerformance Metrics:\n",
    "Accuracy:", round(accuracy, 3), "\n",
    "Precision:", round(precision, 3), "\n",
    "Recall/Sensitivity:", round(recall, 3), "\n",
    "Specificity:", round(specificity, 3), "\n",
    "F1 Score:", round(f1_score, 3), "\n")
```

### Regresja Poissonowska

W przypadku regresji Poissonowskiej funkcją mapującą jest logarytm:\
$$
Y \sim \text{Pois}\left(e^{\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p}\right)
$$

```{r sample poisson}
set.seed(123)
X <- rnorm(100)
Y <- rpois(100, lambda = exp(1 + 0.5 * X))

model <- glm(Y ~ X, family = poisson)

ggplot(data.frame(X, Y), aes(X, Y)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = poisson), se = FALSE) +
  labs(title = "Poisson Regression") +
  theme_minimal()
```

"Ladislaus Josephovich Bortkiewicz ukończył Wydział Prawa w 1890 roku. W
1898 roku opublikował książkę o rozkładzie Poissona, zatytułowaną Prawo
małych liczb. W książce tej po raz pierwszy zauważył, że zdarzenia o
niskiej częstotliwości w dużej populacji mają rozkład Poissona, nawet
jeśli prawdopodobieństwa zdarzeń są różne. To właśnie ta książka
rozsławiła pruskie dane dotyczące kopnięć konia. Dane te podawały liczbę
żołnierzy zabitych w wyniku kopnięcia przez konia każdego roku w każdym
z 14 korpusów kawalerii w okresie 20 lat. Bortkiewicz wykazał, że liczby
te były zgodne z rozkładem Poissona." \~przetłumaczone z
<https://en.wikipedia.org/wiki/Ladislaus_Bortkiewicz>

```{python load kicks}
import pandas as pd

kicks_df = pd.read_csv('kicks.csv', index_col=0)
kicks_df.head()
```

```{python transform kicks}
kicks_long = kicks_df.stack().reset_index()
kicks_long.columns = ['battalion', 'year', 'deaths']
kicks_long['year'] = pd.to_numeric(kicks_long['year'])

kicks_long.head()
```

```{python poisson kicks}
from scipy.stats import poisson
import numpy as np

observed_counts = kicks_long.groupby('deaths').size()
total_corps_years = sum(observed_counts)
observed_props = observed_counts / total_corps_years

lambda_hat = sum(np.array([0,1,2,3,4]) * observed_counts) / total_corps_years
print(f"Estimated lambda: {lambda_hat:.3f}")  # Powinno wynieść około ~0.7

# Wygenerowaqnie prawdopodobieństw z rozkładu poissona
poisson_probs = poisson.pmf(k=[0,1,2,3,4], mu=lambda_hat)
expected_counts = poisson_probs * total_corps_years

results = pd.DataFrame({
    'Deaths': [0,1,2,3,4],
    'Observed': observed_counts,
    'Expected': expected_counts,
    'Observed_%': observed_props*100,
    'Expected_%': poisson_probs*100
})

results
```

```{python fit kicks}
import statsmodels.api as sm

poisson_model = sm.GLM(
    kicks_long['deaths'],
    kicks_long[['battalion', 'year']],
    family=sm.families.Poisson()
).fit()

poisson_model.summary()
```

### Regresja porządkowa

Regresja porządkowa jest rozwinięciem regresji logistycznej. Dla
uporządkowanej zmiennej $Y$ o $K$ kategoriach:\
$$
P(Y \leq k) = \frac{e^{\theta_k - (\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p)}}{1 + e^{\theta_k - (\beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p)}}
$$\
gdzie $\theta_k$ to zakresy (punkty odcięcia) dla każdej kategorii.

Kategorie dopasujemy po prostu po przedziałach wartości, ale z pewnym
dodanym szumem

```{r sample ordered multinomial}
set.seed(123)
X <- rnorm(200)
latent_score <- -2 + 3 * X + rlogis(200)
Y <- cut(latent_score, 
         breaks = c(-Inf, -1, 1, Inf), 
         labels = c("Low", "Medium", "High"),
         ordered_result = TRUE)
```

Tym razem do dopasowania wykorzystamy funkcję polr z pakietu MASS.

```{r fit and visualise ordered multinomial}
library(MASS)

model <- polr(Y ~ X, method = "logistic")

new_data <- data.frame(X = seq(min(X), max(X), length.out = 300))
probs <- predict(model, new_data, type = "probs")

plot_data <- cbind(new_data, probs)
observed_data <- data.frame(X, Y)

ggplot() +
  geom_line(data = plot_data, aes(X, Low, color = "Low"), linewidth = 1) +
  geom_line(data = plot_data, aes(X, Medium, color = "Medium"), linewidth = 1) +
  geom_line(data = plot_data, aes(X, High, color = "High"), linewidth = 1) +
  geom_jitter(data = observed_data, aes(X, as.numeric(Y) / 3 - 0.1, fill = Y), 
              width = 0.05, height = 0.05, shape = 21, size = 2, alpha = 0.6) +
  scale_y_continuous(name = "Probability", limits = c(0, 1)) +
  scale_color_manual("Predicted Probability", 
                     values = c("Low" = "#E41A1C", "Medium" = "#377EB8", "High" = "#4DAF4A")) +
  scale_fill_manual("Observed Data", 
                    values = c("Low" = "#E41A1C", "Medium" = "#377EB8", "High" = "#4DAF4A")) +
  labs(title = "Ordered Multinomial Regression",
       x = "Predictor (X)") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

### Modele do porównania

Powracamy do zbioru danych Titanic.

LDA (Liniowa Analiza Dyskryminacyjna) Metoda statystyczna do
klasyfikacji i redukcji wymiarowości, zakładająca wspólną macierz
kowariancji dla wszystkich klas reprezentawanych przez rokłady normalne.
Optymalizuje liniowe granice decyzyjne

```{r lda titanic}
titanic_lda <- lda(Survived ~ ., data = train_data)
titanic_lda_pred <- predict(titanic_lda, newdata = test_data)
table(Predicted = titanic_lda_pred$class, Actual = test_data$Survived)
```

QDA (Kwadratowa Analiza Dyskryminacyjna) Rozszerzenie LDA, które
dopuszcza różne macierze kowariancji dla każdej klasy, prowadząc do
nieliniowych (kwadratowych) granic decyzyjnych.

```{r qda titanic}
titanic_qda <- qda(Survived ~ ., data = train_data)
titanic_qda_pred <- predict(titanic_qda, newdata = test_data)
table(Predicted = titanic_qda_pred$class, Actual = test_data$Survived) 
```

W tym przypadku nie ma jawnego etapu dopasowania. Funkcja `knn()` z
pakietu `class` od razu wykonuje predykcję. Np. ze zbiorem uczącym i
testowym jak poprzednio i z $k = 1$ mamy

```{r knn titanic}
library(class)
train_x <- model.matrix(Survived ~ ., data = train_data)[,-1]
test_x <- model.matrix(Survived ~ ., data = test_data)[,-1]
train_y <- train_data$Survived

set.seed(123)
titanic_knn <- knn(train_x, test_x, train_y, k = 5)
table(Predicted = titanic_knn, Actual = test_data$Survived) 
```

Ze względu na to, że kNN rozstrzyga remisy losowo, dla zapewnienia
powtarzalności wyników warto przed wywołaniem funkcji `knn`
zainicjalizować generator liczb pseudolosowych (`?set.seed`).
