---
title: "lab3"
author: "Hubert Guzowski"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Regresja liniowa

Będziemy pracować wykorzystując zbiór danych California Housing
(<https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset>),
który zastępuje klasyczny zbiór housing_dt
(<https://scikit-learn.org/1.0/modules/generated/sklearn.datasets.load_housing_dt.html>).

```{python dataset}
from sklearn.datasets import fetch_california_housing
import pandas as pd

housing_df = fetch_california_housing(as_frame=True).frame
housing_df.info()
```

Zadaniem w zbiorze California Housing jest przewidzenie mediany cen
mieszkań w dystryktach stanu Kalifornia (wartosć podana w 100_000\$).

```{python target}
housing_df['MedHouseVal']
```

Zaczniemy wstęp do regresji liniowej od od pracy z R. Ładujemy pakiet
reticulate, aby móc zaimportować dane ze środowiska pythonowego.

```{r import data}
library(reticulate)

housing_dt <- py$housing_df
summary(housing_dt)
```

Dopasowanie (uczenie) modelu liniowego wykonuje się przy pomocy funkcji
`lm()`. Postać modelu określa się przy pomocy **formuły** (czyli obiektu
klasy `formula`). Modelowi

$$
  Y = \beta_0 + \beta_1 X + \epsilon
$$

odpowiada formuła `Y ~ X`. Poniższe instrukcje są równoważne i oznaczają
model

$$
  MedHouseVal = \beta_0 + \beta_1 \cdot MedInc + \epsilon.
$$

```{r simpleRegression}
fit_simple <- lm(housing_dt$MedHouseVal ~ housing_dt$MedInc)
fit_simple <- lm(MedHouseVal ~ MedInc, data = housing_dt)
```

Natomiast poniższa ma działanie szersze

```{r simpleRegressionAttach}
attach(housing_dt)
fit_simple <- lm(MedHouseVal ~ MedInc)
```

Wynikiem w każdym przypadku jest obiekt klasy `lm`, który jest też listą

```{r lmClass}
fit_simple
class(fit_simple)
is.list(fit_simple)
names(fit_simple)
```

Składowe obiektu modelu liniowego są dostępne przez indeksowanie typu
listowego lub przez odpowiednie funkcje/metody akcesorowe (co jest
metodą zalecaną), np.

```{r lmComponents}
fit_simple$coefficients
coef(fit_simple)
```

Dodatkowe informacje można uzyskać przy pomocy funkcji `summary()`

```{r lmSummary}
?summary.lm
summary(fit_simple)
```

Funkcja `summary()` zwraca listę (składowa `sigma` to RSE)

```{r lmSummaryList}
summaryList <- summary(fit_simple)
summaryList$sigma
summaryList$r.squared
summaryList$fstatistic
```

Przedziały ufności dla współczynników regresji oblicza funkcja
`confint()`

```{r confInt}
confint(fit_simple)
```

Funkcja `predict()` oblicza przedziały ufności dla predykcji --- zarówno
dla przewidywania średniej wartości

```{r predictConfidence}
predict(fit_simple, data.frame(MedInc = c(5, 10, 15)), interval = "confidence")
```

jak i dla przewidywania przyszłej wartości

```{r predictPrediction}
predict(fit_simple, data.frame(MedInc = c(5, 10, 15)), interval = "prediction")
```

## Wykresy prostej regresji liniowej

Prosta regresji na tle danych

```{r lmPlot}
plot(housing_dt$MedInc, housing_dt$MedHouseVal)
abline(fit_simple)
```

Wykresy diagnostyczne

```{r lmDiagnosticPlots}
# Można poprzedzić instrukcją: par(mfrow = c(2, 2))
plot(fit_simple)
```

Alternatywnie

```{r lmDiagPlots2}
plot(predict(fit_simple), residuals(fit_simple))
plot(predict(fit_simple), rstudent(fit_simple))
```

Identyfikacja obserwacji wpływowych (statystyka "dźwigni"
[*leverAveRooms*])

```{r hatvalues}
plot(hatvalues(fit_simple))
which.max(hatvalues(fit_simple))
```

## Regresja wielokrotna

Model

$$
  Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3 + \epsilon
$$

reprezentowany jest przez formułę `Y ~ X1 + X2 + X3`, np.

```{r multiRegression}
fit_la <- lm(MedHouseVal ~ MedInc + AveRooms)
summary(fit_la)
```

Jeśli chcemy wykonać regresję pewnej zmiennej względem wszystkich
pozostałych stosuje się składnię (parametr `data` jest tu wymagany)

```{r multiRegressionAll}
fit_all <- lm(MedHouseVal ~ ., data = housing_dt)
summary(fit_all)
```

Regresja z jedną zmienną usuniętą

```{r multiNoAveRooms}
fit_no_AveRooms <- lm(MedHouseVal ~ . - AveRooms, data = housing_dt)
summary(fit_no_AveRooms)
```

Alternatywnie można skorzystać z funkcji `update()`

```{r multiNoAveRoomsUpdate}
fit_no_AveRooms2 <- update(fit_all, ~ . - AveRooms)
summary(fit_no_AveRooms2)
```

## Interakcje między zmiennymi

Obecność składnika $X_1 \cdot X_2$ zaznacza się w formule przez człon
`X1 : X2`. Składnia `X1 * X2` jest skrótem do `X1 + X2 + X1:X2`. Np.

```{r interaction}
summary(lm(MedHouseVal ~ MedInc * AveRooms))
```

## Nieliniowe transformacje predyktorów

Model z kwadratową zależnością od `MedInc`, czyli

$$
  MedHouseVal = \beta_0 + \beta_1 \cdot MedInc + \beta_2 \cdot MedInc^2 + \epsilon
$$

dopasowywany jest następująco (funkcja `I()` jest konieczna ze względu
na specjalne znaczenie operatora `^` w formułach)

```{r square}
fit_l2 <- lm(MedHouseVal ~ MedInc + I(MedInc^2))
summary(fit_l2)
```

Dopasowanie modeli `fit_simple` i `fit_l2` można porównać porównując
$RSE$ i $R^2$. Funkcja `anova()` wykonuje test statystyczny, w którym
hipotezą zerową jest jednakowe dopasowanie.

```{r anova}
anova(fit_simple, fit_l2)
```

Regresja wielomianowa wyższego stopnia może wykorzystywać funkcję
`poly()`

```{r poly}
fit_l5 <- lm(MedHouseVal ~ poly(MedInc, degree=3))
summary(fit_l5)
```

## Zmienne kategoryczne

Nowy zbiór danych 
<https://www.statsmodels.org/stable/datasets/generated/fair.html> odnosi
się do predykcji zdrad w małżeństwach i zawiera wiele tzw. danych
kategorycznych tzn. zakodowanych informacji o przynależności do jednej 
z kategorii.

```{python fair data}
import statsmodels.api as sm

fair_df = sm.datasets.fair.load_pandas().data
fair_df.info()
```

Kategoryczność danych nie zostanie wykryta przy wczytaniu, gdyż są dalej reprezentowane
liczbowo. Poza opisem zbioru danych, informacji na temat kategoryczności może nam
dostarczyć na przykład liczba unikalnych wartości w kolumnie.

```{python fair data}
fair_df.nunique()
```

Zwykle praktycznym sposobem na wykonanie preprocessingu jest w takiej sytuacji
zmapowanie na typ kategoryczny wszystkich wartości o nunique poniżej jakiejś
zadanej odciętej. Niestety zbiór fair jest specyficzny i np. wiek, który jest
oczywiście liczbowy, również ma tylko kilka unikalnych wartości.

```{python fair cat}
categoricals = fair_df.drop(columns=['age', 'children']).loc[:, fair_df.nunique() < 7].astype('category')
others = pd.concat([fair_df.loc[:, fair_df.nunique() >= 7], fair_df[['age', 'children']]], axis=1)
cat_fair_df = pd.concat([others, categoricals], axis=1)
cat_fair_df.info()
```

Możemy dopasować model wykorzystując standardowe api statsmodels.
Model OLS to po prostu regresja liniowa dopasowana prostą metodą najmniejszych
kwadratów (Ordinary LEast Squares) https://www.statsmodels.org/dev/regression.html#model-classes

```{python OLS}
X = cat_fair_df[['age', 'occupation', 'yrs_married']]
X = sm.add_constant(X)
y = cat_fair_df['affairs']

model1 = sm.OLS(y, X).fit()
model1.summary()
```

Ale mamy też dostępne api wykorzystujące obiekt formuły o praktycznie identycznej
składni, co poznane już metody w R.

```{python OLS formula}
import statsmodels.formula.api as smf

model2 = smf.ols('affairs ~ C(age) + religious + yrs_married', data=cat_fair_df).fit()
print(model2.summary())
```

Jak widać, przy użyciu api formula, zmienne kategoryczne zostały odpowiednio 
wykryte przez statsmodels. Dla standardowego api, też możemy osiągnąć ten efekt, 
ale musimy ręcznie zakodować zmienne.

```{python dummy}
dummy_fair_df = pd.get_dummies(cat_fair_df)
dummy_fair_df.info()
```

W pythonie do wizualizacji możemy użyć na przykład plotly:

```{python plotly}
import plotly.express as px

cat_fair_df['predicted_model2'] = model2.predict(cat_fair_df)

fig1 = px.scatter(
    cat_fair_df, 
    x='affairs', 
    y='predicted_model2',
    title='Actual vs Predicted Affairs (Formula API)',
    labels={'affairs': 'Actual Affairs', 'predicted_model2': 'Predicted Affairs'},
    trendline='ols'
)
fig1.show()
```

```{python residuals}
cat_fair_df['residuals_model2'] = cat_fair_df['affairs'] - cat_fair_df['predicted_model2']

fig2 = px.scatter(
    cat_fair_df,
    x='predicted_model2',
    y='residuals_model2',
    title='Residuals vs Fitted Values (Standard API)',
    labels={'predicted_model2': 'Predicted Values', 'residuals_model2': 'Residuals'}
)
fig2.add_hline(y=0, line_dash="dash", line_color="red")
fig2.show()
```

```{python comparison}
model1_coefs = model1.params.reset_index()
model1_coefs.columns = ['Variable', 'Coefficient']
model1_coefs['Model'] = 'Standard API'
model1_coefs['Error'] = model1.bse.values
model1_coefs.iloc[0, 0] = "Intercept"

model2_coefs = model2.params.reset_index()
model2_coefs.columns = ['Variable', 'Coefficient']
model2_coefs['Model'] = 'Formula API'
model2_coefs['Error'] = model2.bse.values

combined_coefs = pd.concat([model1_coefs, model2_coefs])

# Create bar chart of coefficients
fig3 = px.bar(
    combined_coefs,
    x='Variable', 
    y='Coefficient',
    error_y='Error',
    color='Model',
    barmode='group',
    title='Comparison of Model Coefficients',
    labels={'Variable': 'Predictor Variable', 'Coefficient': 'Effect Size'}
)
fig3.show()
```
